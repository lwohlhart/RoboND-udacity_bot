%% V1.0
%% by Gabriel Garcia, gabrcg@gmail.com
%% This is a template for Udacity projects using IEEEtran.cls

%% Be Udacious!

\documentclass[10pt,journal,compsoc]{IEEEtran}

\usepackage[pdftex]{graphicx}    
% \usepackage{cite}
% \hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}

\title{Where Am I?}

\author{Lucas Wohlhart}

\markboth{Localization project, Robotics Nanodegree Program, Udacity}%
{}
\IEEEtitleabstractindextext{%

\begin{abstract}
The goal of the project at hand is the examination of the capabilities of a widely used localization technique known as Adaptive Monte Carlo Localization (AMCL).
This method is based on a particle filter algorithm which will be conceptionally compared to another localization strategy using a Kalman Filter. 
For the evaluation of the localization method, two different robots models are placed in a ROS/Gazebo/RViz simulation environment in which they have to navigate through a maze world to reach a specified goal position.
These two mobile robots both feature a differential drive, one of which is given by the Udacity project description and the creation of the second (custom) robot model will be discussed within this report.
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
Robot, IEEEtran, Udacity, \LaTeX, Localization.
\end{IEEEkeywords}}


\maketitle
\IEEEdisplaynontitleabstractindextext
\IEEEpeerreviewmaketitle
\section{Introduction}
\label{sec:introduction}

\IEEEPARstart{T}{he} capability of accurately determining the pose of a mobile robot is a crucial necessity for being able to autonomously navigate any given environment.
The problem of localization poses three challenges to tackle, which are known as: local localization, global localization and the kidnapped robot problem.
The goal of local localization is to keep track of the pose changes due to robot movement given a known initial pose. In global localization the robots pose starts out as being unknown and the objective is to determine the pose by comparing observations to a ground truth map. The kidnapped robot problem is similar to global localization since the goal is also to find the robots pose without knowing it's initial location, but with the challenging additional constraint that the robot might be randomly placed at an entirely different spot in the world at any time. 
This project tackles the problem of global localization which, if implemented and tuned correctly, enables the robots to autonomously navigate the maze world depicted in Figure~\ref{fig:maze} to reach a specified goal pose. 


%example for inserting image
\begin{figure}[thpb]
      \centering
      \includegraphics[width=\linewidth]{img/maze_world}
      \caption{Maze environment}
      \label{fig:maze}
\end{figure}



\section{Background}
Solving a localization problem boils down to modelling the robots pose changes resulting from the motions executed by the actuators and interpreting the available sensor readings to gather evidence from the environment which can be compared to a known ground truth map.
Both these processes are subject to noise since motions can't be performed with absolute accuracy and sensors don't capture the exact truth about the surrounding world.
The objective of a localization algorithm is therefore to filter out the motion and measurement noise and yield a robust estimation of the robots pose. 

The (Extended) Kalman Filter is a well established method for local localization and will discussed in comparison to the Adaptive Monte Carlo localization particle filter which is able to solve global localization problems.

Since in this project setup the initial pose of the robot is not known, the Adaptive Monte Carlo Localization (AMCL) method was chosen and implemented. Additionally this approach provides a simple way of modelling the nonlinear motions of the robot and is capable of solving the kidnapped robot problem as will be discussed in the following sections.

\subsection{Kalman Filters}
The Kalman Filter is a widely used state estimation algorithm which starts out with an initial state (e.g. a state vector holding the estimated x and y position and the angular orientation of a robot) as well as a covariance matrix expressing the certainty of the estimate and iteratively applies measurement updates and state predictions for each motion step of the robot.

The state prediction step takes the current motion commands of the robot, maps them to the state domain using the predefined state transition matrix and combines the result with the prior state and covariance plus additional gaussian noise to account for noisy motions. This yields the posterior belief about the robots state after a motion step.

The measurement update step uses the measurement function to map the previously calculated posterior state of the prediction step to the measurement domain. This means calculating the expected values of all available sensors, assuming the robot were in this exact state. Computing the difference between this assumption and the actual sensor readings yields the measurement residual.
The so called Kalman Gain is then computed by projecting the covariance to the measurement domain, adding potential measurement noise to all components and reprojecting this result to the state domain. This is a measure indicating the ratio of preserving the previous state estimate and taking in the new measurement evidence. It ranges from a 0-vector which keeps the previous state estimate entirely, to the pseudo inverse of the measurement function which overrides the estimate with the incoming measurement data.

Therefore the Kalman Gain is subsequently used to update the state and covariance estimate.

One drawback of the standard Kalman Filter is that it can't deal with non linear state transitions or measurement functions. Applying a non linear transformation on a Gaussian distribution yields a probability distribution which is non Gaussian and since robots usually perform non linear motions such as driving along a circle or a curve the standard Kalman Filter is not usable for most robotics applications.
To overcome this problem the Extended Kalman Filter (EKF) was introduced which linearizes the non-linear transformations by approximating them with a first order Taylor series expansion. This linearization is only valid for a small region but if the update cycles are short enough the EKF has shown to be able to produce a good and stable state/pose estimation.


\subsection{Particle Filters}
A particle filter algorithm for robot localization starts by instantiating a number of uniformly distributed particles each representing one guess about the position and orientation of the robot. For every particle a weight can be calculated which corresponds to the likelihood of observing the current readings from the available range-finder sensors (e.g.  lidar, RGB-D cameras or others). If a particle matches the observation compared to the ground thruth deduced from the known map better, it gets a bigger weight than others which are less likely. Every motion step of the robot is also applied to each particle with some added noise. After a specific resample interval (usually also every motion step) the particles are then randomly resampled based on their weights and new particles might be spawned in proximity to the previously higher weighted particles. 

By iteratively applying the algorithm:
\begin{itemize}      
      \item motion update: apply robots motion with noise to each particle
      \item sensor update: assign weights to particles based likelihood of matching sensor readings
      \item resample: randomly sample current particle set and insert new particles based on weighted probabilities
\end{itemize}
the particles converge to the true pose of the robot because those which best fit the incoming evidence from the sensors have the highest chance of surviving the resample step.

If correctly configured, the Adaptive Monte Carlo Localization particle filter is even capable of solving the kidnapped robot problem by sparsely inserting particles in randomly chosen remote areas of the particle cloud which allows the algorithm to recover when losing track of the actual pose due to the kidnapping.


\subsection{Comparison / Contrast}

As outlined previously, a major advantage of the Adaptive Monte Carlo Localization method is that it isn't restricted to the assumption of a linear gaussian state space as is the case for a Kalman Filter approach. Any motion or measurement noise model can be used to compute the posterior particle estimates. Furthermore the AMCL is able to solve global localization and even the kidnapped robot problem since it doesn't require an initial state to converge. It is capable of recovering from initial or intermediate erroneous state estimates which makes filter much more robust. 

While the EKF is in general superior in terms of memory and computational efficiency as well as achievable localization accuracy the AMCL allows the user to fully take control of said parameters. By tuning the number of particles used for the filter one can adjust the tradeoff between localization accuracy and resource efficiency to fit the needs of the application.

Table~\ref{tab:mcl_ekf_comparison}, taken from the Udacity lecture "Power of MCL", summarizes the advantages and disadvantages of the discussed localization techniques.


%example for building table
\begin{table}[h]
\caption{MCL vs EKF comparison}
\label{tab:mcl_ekf_comparison}
\begin{center}
\begin{tabular}{|l||c|c|}
\hline
& MCL & EKF\\ \hline \hline
Measurements & Raw Measurements & Landmarks \\ \hline
Measurement Noise &  Any &  Gaussian \\ \hline
Posterior &  Particles & Gaussian \\ \hline
Memory Efficiency & +  & + +  \\ \hline
Time Efficiency&  +  & + +  \\ \hline
Ease of Implementation & + +  & +  \\ \hline
Resolution & +  & + + \\ \hline
Robustness & + +  & - \\ \hline
Memory/Resolution Control & +  & - \\ \hline
Global Localization & +  & - \\ \hline
State Space &  Multimodal Disc. & Unimodal Cont. \\ \hline
\end{tabular}
\end{center}
\end{table}

\section{Simulations}


% package dependencies: from clean install ( either navigation stack or separate packages: move_base, amcl, map_server ... find more)



This section should discuss the performance of robots in simulation. Items to include are the robot model design, packages used, and the parameters chosen for the robot to properly localize itself. The information provided here is critical if anyone would like to replicate your results. After all, the intent of reports such as these are to convey information and build upon ideas so you want to ensure others can validate your process.
You should have at least two images here: one that shows your standard robot used in the first part of the project, and a second robot that you modified / built that is different from the first robot. Remember to watermark all of your images as well. 

\subsection{Achievements}
You should describe what you achieved for localization in the project with the benchmark model and your own model. Includes charts and graphs show how parameters affect your performance. 

% Robot Models
\subsection{Benchmark Model}
\subsubsection{Model design}
The Robot's design considerations should include: the size of the robot, the layout of sensors. This information can be shown in the form of a chart / table.

\begin{figure}[thpb]
      \centering
      \includegraphics[width=\linewidth]{img/udacity_bot}
      \caption{Udacity Bot}
      \label{fig:udacity_bot}
\end{figure}

\subsubsection{Packages Used}
The packages used in the project should be specified as well as the topics received and published; the services it used and provided should also be addressed. 

\subsubsection{Parameters}
Localization parameters in the AMCL node should be described, as well as move\_base parameters in the configuration file. You should be able to clearly demonstrate your understanding of the impact of these parameters.

\subsection{Personal Model}
% ditto
\subsubsection{Model design}
\begin{figure}[thpb]
      \centering
      \includegraphics[width=\linewidth]{img/blender_mse6_chassis}
      \caption{Blender: MSE6 chassis design}
      \label{fig:blender_design_mse6}
\end{figure}

\begin{figure}[thpb]
      \centering
      \includegraphics[width=\linewidth]{img/lw_mse6_bot}
      \caption{MSE6 Bot}
      \label{fig:mse6_bot}
\end{figure}
\subsubsection{Packages Used}
\subsubsection{Parameters}


\section{Results}

Present an unbiased view of your robot's performance and justify your stance with facts. Do the localization results look reasonable? What is the duration for the particle filters to converge? How long does it take for the robot to reach the goal? Does it follow a smooth path to the goal? Does it have unexpected behavior in the process? \\
For demonstrating your results, it is incredibly useful to have some watermarked charts, tables, and/or graphs for the reader to review. This makes ingesting the information quicker and easier.

\subsection{Localization Results}
\subsubsection{Benchmark}
\begin{figure}[thpb]
      \centering
      \includegraphics[width=\linewidth]{img/particles_initial}
      \caption{Initial AMCL particles}
      \label{fig:initial_amcl_particles}
\end{figure}
\begin{figure}[thpb]
      \centering
      \includegraphics[width=\linewidth]{img/udacity_bot_goal_location}
      \caption{Udacity Bot at goal location}
      \label{fig:udacity_bot_goal_location}
\end{figure}




\subsubsection{Student}

\begin{figure}[thpb]
      \centering
      \includegraphics[width=\linewidth]{img/lw_mse6_bot_particles_converged}
      \caption{AMCL particles converging}
      \label{fig:amcl_particles_converging}
\end{figure}
\begin{figure}[thpb]
      \centering
      \includegraphics[width=\linewidth]{img/lw_mse6_bot_goal_location}
      \caption{MSE6 Bot at goal location}
      \label{fig:mse6_bot_goal_location}
\end{figure}

\subsection{Technical Comparison} % only facts
Discuss the difference of the layout, parameters, performance etc. between the benchmark robot and your robot. It is acceptable for your custom robot to perform worse than the provided robot. The focus is on learning and understanding, not performance. 

\section{Discussion}
This is the only section of the report where you may include your opinion. However, make sure your opinion is based on facts. If your robot performed poorly, make mention of what may be the underlying issues. If the robot runs well, which aspects contribute to that? Again, avoid writing in the first person (i.e. Do not use words like "I" or "me"). If you really find yourself struggling to avoid the word "I" or "me"; sometimes, this can be avoid with the use of the word “one”. As an example: instead of : "I think the robot cannot localize itself because the sensor does not provide enough information for localization" try: "one may believe the localization performance is poor because the sensor layout is not able to provide enough information for localization". They say the same thing, but the second avoids the first person. 

\subsection{Topics}
\begin{itemize}
\item Which robot performed better?
\item Why it performed better? (opinion)
\item How would you approach the 'Kidnapped Robot' problem?
\item What types of scenario could localization be performed?
\item Where would you use MCL/AMCL in an industry domain?
\end {itemize}

\section{Conclusion / Future work}
This section is intended to summarize your report. Your summary should include a recap of the results, did this project achieve what you attempted, how would you deploy it on hardware and how could this project be applied to commercial products? 
For Future Work, address areas of work that you may not have addressed in your report as possible next steps. This could be due to time constraints, lack of currently developed methods / technology, and areas of application outside of your current implementation. Again, avoid the use of the first-person.

\subsection{Modifications for Improvement}
Examples:
\begin{itemize}
\item Base Dimension
\item Sensor Location
\item Sensor Layout
\item Sensor Amount
\end{itemize}

\cite{lamport1994latex}


\bibliography{bib}
\bibliographystyle{ieeetr}

\end{document}